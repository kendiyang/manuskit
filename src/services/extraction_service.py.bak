"""
Web content extraction service using Steel SDK and browser-use.
Implements intelligent content extraction from web pages.
"""
import asyncio
import logging
import os
import json
import re
from typing import Optional, Dict, Any, List
from steel import Steel
from browser_use import Agent, BrowserSession
from langchain_openai import ChatOpenAI

from src.models import ExtractionResult, ContentSection, PostMetadata

logger = logging.getLogger(__name__)


def replace_protocol_mapping(url: str) -> str:
    """Convert HTTP/HTTPS protocol to WebSocket protocol"""
    protocol_mapping = {
        'http://': 'ws://',
        'https://': 'wss://'
    }
    
    for old_protocol, new_protocol in protocol_mapping.items():
        if url.startswith(old_protocol):
            return url.replace(old_protocol, new_protocol)
    return url


class ExtractionService:
    """Service for extracting structured content from websites"""
    
    def __init__(
        self,
        steel_api_key: Optional[str] = None,
        steel_base_url: Optional[str] = None,
        openai_api_key: Optional[str] = None,
        openai_base_url: Optional[str] = None,
        model: str = "gpt-4o"
    ):
        """
        Initialize extraction service
        
        Args:
            steel_api_key: Steel API key (defaults to STEEL_API_KEY env var)
            steel_base_url: Optional custom Steel endpoint
            openai_api_key: OpenAI API key (defaults to OPENAI_API_KEY env var)
            openai_base_url: Optional custom OpenAI endpoint
            model: LLM model to use for extraction
        """
        self.steel_api_key = steel_api_key or os.getenv("STEEL_API_KEY", "")
        self.steel_base_url = steel_base_url or os.getenv("STEEL_BASE_URL")
        self.openai_api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        self.openai_base_url = openai_base_url or os.getenv("OPENAI_BASE_URL")
        self.model = model or os.getenv("MODEL", "gpt-4o")
        
        # Log configuration (mask sensitive data)
        logger.info(f"Initializing ExtractionService with model: {self.model}")
        logger.info(f"Steel Base URL: {self.steel_base_url}")
        logger.info(f"OpenAI Base URL: {self.openai_base_url}")
        logger.info(f"Steel API Key configured: {bool(self.steel_api_key and self.steel_api_key.strip())}")
        logger.info(f"OpenAI API Key configured: {bool(self.openai_api_key)}")
        
        if not self.steel_api_key or not self.steel_api_key.strip():
            logger.warning("STEEL_API_KEY is not configured - this may cause issues")
        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEY is required")
    
    def _create_steel_client(self) -> Steel:
        """Create Steel client instance"""
          def _create_llm(self) -> ChatOpenAI:
        """Create LLM instance for AI agent"""
        logger.info(f"Creating LLM with model: {self.model}")
        return ChatOpenAI(
            model=self.model,
            temperature=0.3,
            api_key=self.openai_api_key,
            base_url=self.openai_base_url,
        )
    
    async def extract_reddit_answers(self, question: str) -> ExtractionResult:
        """
        Extract structured content from Reddit Answers for a given question.
        
        Args:
            question: Question to search for on Reddit Answers
            
        Returns:
            ExtractionResult with structured data
        """
        steel_client = None
        session = None
        
        try:
            logger.info(f"Starting extraction for question: {question}")
            
            # Decide whether to use Steel (if credentials or base URL provided)
            use_steel = bool((self.steel_api_key and self.steel_api_key.strip()) or self.steel_base_url)
            browser_session = None
            
            if use_steel:
                # Create Steel session
                steel_client = self._create_steel_client()
                session = steel_client.sessions.create()
                logger.info(f"Steel session created: {session.session_viewer_url}")
                
                # Connect browser-use to Steel via CDP
                domain = self.steel_base_url or os.getenv("DOMAIN", "http://localhost:3000")
                cdp_url = replace_protocol_mapping(domain)
                logger.info(f"Connecting to CDP URL: {cdp_url}")
                browser_session = BrowserSession(cdp_url=cdp_url)
            else:
                logger.info("STEEL not configured — running with local browser session")
                browser_session = BrowserSession()
            
            # Create AI agent with extraction task
            llm = self._create_llm()
            
            # Detailed extraction prompt for Reddit Answers
            task = f"""
            Go to https://www.reddit.com/answers/ and search for: "{question}"
            
            Then extract and structure the following information:
            1. The full URL of the Reddit Answers page
            2. The exact question as displayed
            3. All source subreddit URLs mentioned
            4. All answer sections with their headings and content (as separate paragraphs)
            5. Related posts with rank, title, subreddit, URL, upvotes, comments, domain, promoted status, and score
            6. Related topics/questions suggested
            
            Return the data in JSON format following this structure:
            {{
                "url": "full URL",
                "question": "the question",
                "sources": ["list", "of", "subreddit", "urls"],
                "sections": [
                    {{"heading": "Section Name", "content": ["paragraph 1", "paragraph 2"]}}
                ],
                "relatedPosts": [
                    {{
                        "rank": "1",
                        "title": "Post title",
                        "subreddit": "subreddit_name",
                        "url": "post url",
                        "upvotes": 123,
                        "comments": 45,
                        "domain": "domain",
                        "promoted": false,
                        "score": 123
                    }}
                ],
                "relatedTopics": ["related question 1", "related question 2"]
            }}
            """
            
            agent = Agent(
                task=task,
                llm=llm,
                browser_session=browser_session
            )
            
            # Run the agent
            logger.info("Running AI agent for content extraction...")
            result = await agent.run()
            
            # Parse agent result - the agent should return structured data
            logger.info("Extraction completed, parsing results...")
            
            # The agent.run() returns agent output - we need to extract the final result
            # For now, create a structured result from the agent's history
            extraction_result = self._parse_agent_result(result, question)
            
            logger.info(f"Successfully extracted data for: {question}")
            return extraction_result
            
        except Exception as e:
            logger.error(f"Extraction failed: {str(e)}", exc_info=True)
            raise
        
        finally:
            # Clean up Steel session if used
            if steel_client and session:
                try:
                    steel_client.sessions.release(session.id)
                    logger.info("Steel session released")
                except Exception as e:
                    logger.warning(f"Failed to release Steel session: {e}")
    
    def _parse_agent_result(self, agent_result: Any, question: str) -> ExtractionResult:
        """
        Parse agent result into structured ExtractionResult.
        
        Args:
            agent_result: Result from agent.run()
            question: Original question
            
        Returns:
            ExtractionResult object
        """
        # Try to extract JSON from agent result
        # The agent should have the final extracted data in its history or output
        
        # For now, return a basic structure - in production, this would parse
        # the actual agent output which should contain the extracted JSON
        
        # Placeholder - in real implementation, parse from agent_result
        # This would look into agent_result.final_result() or similar
        
        result_data = {
            "url": "https://www.reddit.com/answers/",
            "question": question,
            "sources": [],
            "sections": [],
            "relatedPosts": [],
            "relatedTopics": []
        }
        
        # Try to extract JSON from agent result if available
        if hasattr(agent_result, 'final_result'):
            try:
                final_result = agent_result.final_result()
                if isinstance(final_result, str):
                    # Try to parse JSON from string
                    json_match = re.search(r'\{.*\}', final_result, re.DOTALL)
                    if json_match:
                        result_data = json.loads(json_match.group(0))
            except (AttributeError, json.JSONDecodeError) as e:
                logger.warning(f"Failed to parse agent result as JSON: {e}")
        
        return ExtractionResult(**result_data)
    
    async def extract_generic_content(
        self,
        url: str,
        extraction_instructions: str
    ) -> Dict[str, Any]:
        """
        Extract content from any website with custom instructions.
        
        Args:
            url: Target URL
            extraction_instructions: What to extract and how
            
        Returns:
            Dictionary with extracted content
        """
        steel_client = None
        session = None
        
        try:
            logger.info(f"Starting generic extraction from: {url}")
            
            # Decide whether to use Steel (if credentials or base URL provided)
            use_steel = bool(self.steel_api_key or self.steel_base_url)
            browser_session = None
            if use_steel:
                steel_client = self._create_steel_client()
                session = steel_client.sessions.create()
                # Connect browser-use to Steel
                domain = os.getenv("DOMAIN", "http://localhost:3000")
                cdp_url = replace_protocol_mapping(domain)
                browser_session = BrowserSession(cdp_url=cdp_url)
            else:
                logger.info("STEEL_API_KEY not provided — running with local browser session")
                browser_session = BrowserSession()

            # Create AI agent
            llm = self._create_llm()
            task = f"Go to {url} and {extraction_instructions}"
            
            agent = Agent(
                task=task,
                llm=llm,
                browser_session=browser_session
            )
            
            # Run extraction
            result = await agent.run()
            
            # Return raw result
            return {"url": url, "result": str(result)}
            
        finally:
            if steel_client and session:
                try:
                    steel_client.sessions.release(session.id)
                except Exception as e:
                    logger.warning(f"Failed to release Steel session: {e}")
